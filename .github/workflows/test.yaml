# Inspired by xarray

name: Test

on:
  pull_request:
    branches:
      - "*"
  push:
    branches:
      - main

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    name: ${{ matrix.os }} py${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest", "macos-latest", "windows-latest"]
        python-version: ["3.9", "3.12"]
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup micromamba
        uses: mamba-org/setup-micromamba@v2
        with:
          environment-name: numbagg-tests
          cache-environment: true
          cache-environment-key: "${{matrix.os}}-${{matrix.python-version}}"
          create-args: >-
            python=${{matrix.python-version}} numba pandas bottleneck pytest pytest-benchmark hypothesis tabulate pyarrow

      - name: Install numbagg
        run: |
          python -m pip install -e .[dev]

      - name: Run tests
        run: |
          python -m pytest --durations=20 -W error

  benchmark:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest"]
        python-version: ["3.12"]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup micromamba
        uses: mamba-org/setup-micromamba@v2
        with:
          environment-name: numbagg-tests
          cache-environment: true
          cache-environment-key: "${{matrix.os}}-${{matrix.python-version}}"
          create-args: >-
            python=${{matrix.python-version}} numba pandas bottleneck pytest pytest-benchmark hypothesis tabulate pyarrow

      - name: Install numbagg
        run: |
          python -m pip install -e .[dev]

      - name: Run benchmarks
        run: |
          micromamba run -n numbagg-tests python numbagg/test/run_benchmarks.py

  nightly:
    # Only run on merges to main (could also add a schedule or something similar)
    # All is copied from above apart from the `--run-nightly` & `--benchmark-enable` flags
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest"]
        python-version: ["3.12"]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup micromamba
        uses: mamba-org/setup-micromamba@v2
        with:
          environment-name: numbagg-tests
          cache-environment: true
          cache-environment-key: "${{matrix.os}}-${{matrix.python-version}}"
          create-args: >-
            python=${{matrix.python-version}} numba pandas bottleneck pytest pytest-benchmark hypothesis tabulate pyarrow

      - name: Install numbagg
        run: |
          python -m pip install -e .[dev]

      - name: Run benchmarks
        run: |
          python -m pytest --durations=20 -W error --run-nightly --benchmark-enable

  mypy:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest"]
        python-version: ["3.11"]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup micromamba
        uses: mamba-org/setup-micromamba@v2
        with:
          environment-name: numbagg-tests
          cache-environment: true
          cache-environment-key: "${{matrix.os}}-${{matrix.python-version}}"
          create-args: >-
            python=${{matrix.python-version}} numba pandas bottleneck pytest pytest-benchmark hypothesis tabulate pyarrow

      - name: Install numbagg
        run: |
          python -m pip install -e .[dev]

      - name: Mypy
        run: |
          mypy
